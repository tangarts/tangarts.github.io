
<html>
    <head> 
        <meta charset='utf-8' />
        <meta name="viewport" content="width=device-width, initial-scale=1">

        <link rel= "stylesheet" href="/static/css/style.css" type="text/css">
        <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
        <!-- KaTex -->
        <link rel="stylesheet"
              href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"
              crossorigin="anonymous">

        <title> Monte Carlo </title>
    </head>

    <body>
        <div class="container">
            <header> 
                <a id=logo href='/'> tangarts </a> 
                <div id="header_wrap" class="wrapper">
                    <nav id="navbar">
                        <ul class="list-none" >
                            <li><a href="/about">about</a> &centerdot;</li>
                            <li><a href="/archives.html">archive</a> &centerdot;</li>
                            <li><a href="/now">now</a> &centerdot;</li>
                            <li><a href="mailto:nehemiahcampbell@hotmail.co.uk">contact</a></li>
                        </ul> 

                    </nav>
                </div>

            </header>  
            <main class="wrapper">

                <hr> 


<h1> Monte Carlo </h1>
<div class=date>
        2021-04-24
        | Modified: 2021-04-24

</div>

<article><p>Monte Carlo methods are a class of sampling algorithms to obtain numerical approximations.
To do this we rely on the weak law of large numbers:</p>
<dl>
<dt><strong>The weak law of large numbers</strong></dt>
<dd>
<p>A sequence of random variables <span class="math">\(X_1, X_2, \cdots, X_n\)</span> <em>converges in probability</em> to a random
variable <span class="math">\(X\)</span> if for all <span class="math">\(\delta &gt; 0\)</span>
<div class="math">$$
    \lim_{n\rightarrow \infty} \mathbb P(|X_n - X | \geq \delta) = 0.
$$</div>
</p>
</dd>
</dl>
<p>This is also written as <span class="math">\(X_n \overset{\text{p}}\rightarrow X\)</span></p>
<dl>
<dt>A consequence of this taking using the empirical mean <span class="math">\(\overline{X}_n = \frac{1}{n} \sum_{i=1}^n X_i\)</span></dt>
<dd>
<p>If the sequence <span class="math">\(X_1, X_2, \cdots\)</span> are independent and identically distributed (i.i.d) with <span class="math">\(\mathbb E(X_1) = \mu\)</span> and
finite variance <span class="math">\(\sigma^2 &lt; \infty\)</span>,  we have <span class="math">\(\overline{X}_n \overset{\text{p}}\rightarrow \mu\)</span></p>
</dd>
</dl>
<p>For an illustrated example we'll use an abstract example of estimating the probability that <span class="math">\(X \in A\)</span> for a set <span class="math">\(A \subset \mathbb R\)</span>. We also assume <span class="math">\(X\)</span> has probability density function <span class="math">\(\pi\)</span>.</p>
<p>Defining the estimator of a sample landing in <span class="math">\(A\)</span> as <span class="math">\(\hat{p} := \boldsymbol{1}_{X_n \in A}\)</span> we notice that <span class="math">\(\mathbb P(X \in A) = \mathbb E[\boldsymbol{1}_{X_n \in A}]\)</span> thus we approximate <span class="math">\(\mathbb P(X \in A)\)</span> with the empirical mean <span class="math">\(\frac{1}{n} \sum_{i=1}^n \boldsymbol{1}_{X_i \in A}\)</span></p>
<p>where
</p>
<div class="math">$$\boldsymbol{1}_{X_i \in A} = \left\{
\begin{array}{ll}
1 &amp;  X_i \in A \\
0 &amp; \text{otherwise}
\end{array} 
\right.$$</div>
<p>The estimator <span class="math">\(\hat{p}\)</span> describes the proportion of samples landing in <span class="math">\(A\)</span>. If we define <span class="math">\(Z_n\)</span> as the <em>number</em> of samples landing in <span class="math">\(A\)</span> the we have the relationship <span class="math">\(\hat{p} = \dfrac{Z_n}{n}\)</span>.</p>
<p>It follows that the number of samples that land in <span class="math">\(A\)</span> follows a Binomial distribution <span class="math">\(Z_n \sim \text{Bin}(n, p)\)</span>. This arises from considering the sum of <span class="math">\(n\)</span> independent Bernoulli trials.</p>
<!--
#### The limitations of Monte Carlo simulations

As we know the distribution of $\hat{p}$ we can calculate the variance of the estimator:
$$
    \text{Var}(\hat{p}) = \frac{1}{n^2}\text{Var}(Z_n) = \frac{np(1 - p)}{n^2} = \frac{p(1 - p)}{n}.
$$
The empirical mean $\mathbb E[\hat{p}] = \frac{1}{n}\mathbb E[Z_n] = p$ thus using the weak law of large numbers, $\hat{p} \overset{\text{p}}\rightarrow p$.

How do we quantify how close $\hat{p}$ is to $p$? First we introduce the Central Limit theorem:

: For $X_1, X_2, \cdots, X_n$, $n$ i.i.d samples with mean $\mu$ and finite variance $\sigma^2$ with $\overline{X}_n$ defining the empirical mean,
$$Z = lim_{n \rightarrow \infty} \sqrt{n}\left( \frac{\overline{X}_n - \mu}{\sigma}\right) \sim \mathcal N(0, 1)$$

The consequence of the theorem tells us 
for large $n$ $\overline{Z}_n \sim \mu + \frac{\sigma}{\sqrt{n}}Z$
Which for our parameters of interest:
$$p + \frac{\sqrt{p(1-p)}}{\sqrt{n}}Z$$

$p$ the quantity of interest and $\frac{\sqrt{p(1-p)}}{\sqrt{n}}Z$ the error term. As $Z \in (0, 1)$ we take the error term to be $\frac{\sqrt{p(1-p)}}{\sqrt{n}}$

Finally, we see the error term shrinks by a factor of $\sqrt{n}$. 
-->

<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script></article>



            </main> 

            <footer>
                <p>&centerdot; &centerdot; &centerdot;</p> 
            </footer>

        </div>
    </body>
</html>
