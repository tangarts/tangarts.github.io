
<html>
    <head> 
    <meta charset='utf-8' />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel= "stylesheet" href="/static/css/style.css" type="text/css">
    <link rel="shortcut icon" href="/favicon.ico" type="image/ico"/>
    <title> Learning the XOR function with an LSTM </title>
    </head>
    
    <body>
            <div class="container">
	    <header>
                    <h1> <a href='/'> tangarts </a> </h1>
                    <div id="header_wrap" class="wrapper">
                    <nav id="navbar" >
                <ul class="list-none" >
                        <li><a href="/about">about</a> &centerdot;</li>
                <li><a href="/archives.html">archive</a> &centerdot;</li>
                <li><a href="/now">now</a> &centerdot;</li>
                <li><a href="mailto:nehemiahcampbell@hotmail.co.uk">contact</a></li>
                </ul> 

                    </nav>
                    </div>

            </header>  
        <main class="wrapper">

                       <hr> 


<h1> Learning the XOR function with an LSTM </h1>
<div class=date>
        2020-08-04

</div>

<article><p><strong>Problem Statement:</strong> </p>
<p>Train an LSTM to solve the XOR problem: that is, given a sequence of bits,
determine its parity. The LSTM should consume the sequence, one bit at a time,
and then output the correct answer at the sequenceâ€™s end. </p>
<p>Test the two approaches below:</p>
<ul>
<li>Generate a dataset of random 100,000 binary strings of length 50. Train the
  LSTM; what performance do you get?</li>
<li>Generate a dataset of random 100,000 binary strings, where the length of each
  string is independently and randomly chosen between 1 and 50. Train the LSTM.
  Does it succeed? What explains the difference?</li>
</ul>
<p>LSTM networks have been used with success on sequential data. </p>
<p>A great introduction to recurrent neural networks, specifically LSTM (long
short-term memory) networks can be found reading through Chris Olah's
explanation on <a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/">understanding
LSTMs</a>.</p>
<p>In the problem statement it specifies "The LSTM should consume the sequence,
one but at a time &hellip;"</p>
<p>As we are considering sequential data it seems that an LSTM would be a good
architectural choice in training a neural network to learn the parity of
a sequence of bits. </p>
<dl>
<dt><strong>parity.</strong></dt>
<dd>
<p>The parity of a sequence checks the number of 1-bits. In our case we will
consider odd-parity, the function returning 1 if the number of bits in
a sequence is odd, 0 if even.</p>
</dd>
<dt><strong>parity function.</strong></dt>
<dd>
<p>The function takes in a sequence of bits and returns the parity bit of the</p>
</dd>
<dd>
<p>sequence. Returning 1 if the sequence contains an odd amount of 1-bits,</p>
</dd>
<dd>
<p>0 otherwise.</p>
</dd>
</dl>
<p>The parity function can be written as </p>
<div class="math">$$f(\textbf{x}) = x_1 \oplus x_2 \oplus \ldots \oplus x_n$$</div>
<p>where <span class="math">\(\oplus\)</span> is the XOR function defined by the table below</p>
<table>
<thead>
<tr>
<th>A</th>
<th>B</th>
<th>A <span class="math">\(\oplus\)</span> B</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>1</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>0</td>
</tr>
</tbody>
</table>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">operator</span>
<span class="kn">import</span> <span class="nn">functools</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="k">def</span> <span class="nf">foldl</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="n">xs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">functools</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">acc</span><span class="p">)</span>  

<span class="n">foldl</span><span class="p">(</span><span class="n">operator</span><span class="o">.</span><span class="n">add</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">10</span><span class="p">])</span>

<span class="o">&gt;&gt;</span> <span class="mi">55</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="ch">#!python</span>

<span class="c1"># parity check, function = xor, acc = 0 sequece, 0s and 1s</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;bitstring     |  parity &quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="o">*</span><span class="mi">25</span><span class="p">)</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">seq</span> <span class="o">=</span> <span class="p">[</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">12</span><span class="p">)]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">b</span><span class="p">)</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">seq</span><span class="p">)</span><span class="si">}</span><span class="s2">  |    </span><span class="si">{</span><span class="n">foldl</span><span class="p">(</span><span class="n">operator</span><span class="o">.</span><span class="n">xor</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">seq</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="o">&gt;&gt;</span>    <span class="n">bitstring</span>     <span class="o">|</span>  <span class="n">parity</span> 
<span class="o">&gt;&gt;</span>    <span class="o">-------------------------</span>
<span class="o">&gt;&gt;</span>    <span class="mi">001011110010</span>  <span class="o">|</span>    <span class="mi">0</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">trace_xor</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    shows the intermediate steps of </span>
<span class="sd">    xor function on </span>
<span class="sd">    a sequence</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">operator</span><span class="o">.</span><span class="n">xor</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">a</span><span class="si">}</span><span class="s2"> XOR </span><span class="si">{</span><span class="n">b</span><span class="si">}</span><span class="s2"> = </span><span class="si">{</span><span class="n">result</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span>

<span class="nb">print</span><span class="p">(</span><span class="n">foldl</span><span class="p">(</span><span class="n">trace_xor</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]))</span>

<span class="o">&gt;&gt;</span>    <span class="mi">0</span> <span class="n">XOR</span> <span class="mi">1</span> <span class="o">=</span> <span class="mi">1</span>
<span class="o">&gt;&gt;</span>    <span class="mi">1</span> <span class="n">XOR</span> <span class="mi">0</span> <span class="o">=</span> <span class="mi">1</span>
<span class="o">&gt;&gt;</span>    <span class="mi">1</span> <span class="n">XOR</span> <span class="mi">0</span> <span class="o">=</span> <span class="mi">1</span>
<span class="o">&gt;&gt;</span>    <span class="mi">1</span> <span class="n">XOR</span> <span class="mi">1</span> <span class="o">=</span> <span class="mi">0</span>
<span class="o">&gt;&gt;</span>    <span class="mi">0</span> <span class="n">XOR</span> <span class="mi">1</span> <span class="o">=</span> <span class="mi">1</span>
<span class="o">&gt;&gt;</span>    <span class="mi">1</span>
</code></pre></div>

<p>The middle column corresponds to our bit string we want to check. Notice the
left column is the previous result from XOR(a, b). As a consequence, the final
result only depends on xor of the previously returned result. In our example the
last bit of our sequence being 1 and the previously returned XOR result, 0. </p>
<h2>Experiment</h2>
<ul>
<li>Generating parity data </li>
<li>Training and evaluating LSTM</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.utils.data</span> <span class="k">as</span> <span class="nn">data</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="n">device</span> <span class="o">=</span> <span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="c1"># Data</span>
<span class="n">TRAINING_SIZE</span>   <span class="o">=</span> <span class="mi">100000</span>
<span class="n">VALIDATION_SIZE</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">BIT_LEN</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">VARIABLE_LEN</span> <span class="o">=</span> <span class="kc">True</span>

<span class="c1"># Model Parameters</span>
<span class="n">INPUT_SIZE</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">HIDDEN_SIZE</span> <span class="o">=</span>  <span class="mi">2</span>
<span class="n">NUM_LAYERS</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1"># Training Parameters</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">LEARNING_RATE</span> <span class="o">=</span> <span class="mf">0.01</span> <span class="c1"># DEFAULT ADAM 0.001</span>

<span class="n">THRESHOLD</span> <span class="o">=</span> <span class="mf">0.0001</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">XOR</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; GENERATE XOR DATA &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample_size</span><span class="o">=</span><span class="n">VALIDATION_SIZE</span><span class="p">,</span> <span class="n">bit_len</span><span class="o">=</span><span class="n">BIT_LEN</span><span class="p">,</span> <span class="n">variable</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bit_len</span> <span class="o">=</span> <span class="n">bit_len</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sample_size</span> <span class="o">=</span> <span class="n">sample_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">variable</span> <span class="o">=</span> <span class="n">VARIABLE_LEN</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate_data</span><span class="p">(</span><span class="n">sample_size</span><span class="p">,</span> <span class="n">bit_len</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="n">index</span><span class="p">,</span> <span class="p">:],</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">)</span>


    <span class="k">def</span> <span class="nf">generate_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample_size</span><span class="p">,</span> <span class="n">seq_length</span><span class="o">=</span><span class="n">BIT_LEN</span><span class="p">):</span>

        <span class="n">bits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">sample_size</span><span class="p">,</span> <span class="n">seq_length</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">variable</span><span class="p">:</span>
            <span class="c1"># we generate random integers and pad the bits with zeros</span>
            <span class="c1"># to mimic variable bit string lengths </span>
            <span class="c1"># padding with zeros as they do not provide information</span>
            <span class="c1"># TODO: vectorize instead of loop?</span>
            <span class="n">pad</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">seq_length</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">sample_size</span><span class="p">,</span> <span class="p">))</span>
            <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">pad</span><span class="p">):</span>
                <span class="n">bits</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="n">p</span><span class="p">:]</span> <span class="o">=</span> <span class="mf">0.</span>

        <span class="n">bitsum</span> <span class="o">=</span> <span class="n">bits</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># if bitsum[i] odd: -&gt; True</span>
        <span class="c1"># else: False</span>
        <span class="n">parity</span> <span class="o">=</span> <span class="p">(</span><span class="n">bitsum</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">bits</span><span class="p">,</span> <span class="n">parity</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">XORLSTM</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">XORLSTM</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span>  <span class="o">=</span> <span class="n">num_layers</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span>  <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">lengths</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="n">h0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">c0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="c1"># Forward propagate LSTM</span>
        <span class="n">out_lstm</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">h0</span><span class="p">,</span> <span class="n">c0</span><span class="p">))</span>  
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">out_lstm</span><span class="p">)</span>

        <span class="n">predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">predictions</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">model</span> <span class="o">=</span> <span class="n">XORLSTM</span><span class="p">(</span><span class="n">INPUT_SIZE</span><span class="p">,</span> <span class="n">HIDDEN_SIZE</span><span class="p">,</span> <span class="n">NUM_LAYERS</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">LEARNING_RATE</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="c1"># train</span>
<span class="k">def</span> <span class="nf">train</span><span class="p">():</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
                    <span class="n">XOR</span><span class="p">(</span><span class="n">TRAINING_SIZE</span><span class="p">,</span> <span class="n">BIT_LEN</span><span class="p">,</span> <span class="n">VARIABLE_LEN</span><span class="p">),</span> 
                    <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span>
                    <span class="p">)</span>
    <span class="n">total_step</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training...</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-&#39;</span><span class="o">*</span><span class="mi">60</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">EPOCHS</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">step</span><span class="p">,</span> <span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
            <span class="n">features</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">features</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="c1"># Forward pass</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

            <span class="c1"># Backward and optimize</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="n">accuracy</span> <span class="o">=</span> <span class="p">((</span><span class="n">outputs</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">==</span> <span class="p">(</span><span class="n">labels</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">))</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

            <span class="k">if</span> <span class="p">(</span><span class="n">step</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">250</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;Epoch [</span><span class="si">{}</span><span class="s1">/</span><span class="si">{}</span><span class="s1">], Step [</span><span class="si">{}</span><span class="s1">/</span><span class="si">{}</span><span class="s1">], Loss: </span><span class="si">{:.4f}</span><span class="s1">, Accuracy: </span><span class="si">{:.3f}</span><span class="s1">&#39;</span> 
                       <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">EPOCHS</span><span class="p">,</span> 
                        <span class="n">step</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">total_step</span><span class="p">,</span> 
                        <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">accuracy</span><span class="p">))</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-&#39;</span><span class="o">*</span><span class="mi">60</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">accuracy</span> <span class="o">-</span> <span class="mf">1.0</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">THRESHOLD</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;EARLY STOPPING&quot;</span><span class="p">)</span>
                    <span class="k">return</span>

            <span class="k">if</span> <span class="n">step</span><span class="o">+</span><span class="mi">1</span>  <span class="o">==</span> <span class="n">total_step</span><span class="p">:</span>
                <span class="n">valid_accuracy</span> <span class="o">=</span> <span class="n">validate</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;validation accuracy: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">valid_accuracy</span><span class="p">))</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-&#39;</span><span class="o">*</span><span class="mi">60</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">valid_accuracy</span> <span class="o">-</span> <span class="mf">1.0</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">THRESHOLD</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;EARLY STOPPING&quot;</span><span class="p">)</span>
                    <span class="k">return</span> 
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">validate</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="n">valid_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
                    <span class="n">XOR</span><span class="p">(</span><span class="n">VALIDATION_SIZE</span><span class="p">,</span> <span class="n">BIT_LEN</span><span class="p">,</span> <span class="n">VARIABLE_LEN</span><span class="p">),</span> 
                        <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span>
                        <span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="mf">0.</span>
    <span class="n">total</span> <span class="o">=</span> <span class="mf">0.</span>
    <span class="k">for</span> <span class="n">features</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">valid_loader</span><span class="p">:</span>
        <span class="n">features</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">features</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
            <span class="n">total</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">*</span><span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">correct</span> <span class="o">+=</span> <span class="p">((</span><span class="n">outputs</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">==</span> <span class="p">(</span><span class="n">labels</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">train</span><span class="p">()</span>

<span class="o">&gt;&gt;</span>    <span class="n">Training</span><span class="o">...</span>
<span class="o">&gt;&gt;</span>    
<span class="o">&gt;&gt;</span>    <span class="o">------------------------------------------------------------</span>
<span class="o">&gt;&gt;</span>    <span class="n">Epoch</span> <span class="p">[</span><span class="mi">1</span><span class="o">/</span><span class="mi">8</span><span class="p">],</span> <span class="n">Step</span> <span class="p">[</span><span class="mi">250</span><span class="o">/</span><span class="mi">12500</span><span class="p">],</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.7235</span><span class="p">,</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">0.375</span>
<span class="o">&gt;&gt;</span>    <span class="o">------------------------------------------------------------</span>
<span class="o">&gt;&gt;</span>    <span class="n">Epoch</span> <span class="p">[</span><span class="mi">1</span><span class="o">/</span><span class="mi">8</span><span class="p">],</span> <span class="n">Step</span> <span class="p">[</span><span class="mi">500</span><span class="o">/</span><span class="mi">12500</span><span class="p">],</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.6935</span><span class="p">,</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">0.460</span>
<span class="o">&gt;&gt;</span>    <span class="o">------------------------------------------------------------</span>
<span class="o">&gt;&gt;</span>    <span class="n">Epoch</span> <span class="p">[</span><span class="mi">1</span><span class="o">/</span><span class="mi">8</span><span class="p">],</span> <span class="n">Step</span> <span class="p">[</span><span class="mi">750</span><span class="o">/</span><span class="mi">12500</span><span class="p">],</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.6767</span><span class="p">,</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">0.618</span>
<span class="o">&gt;&gt;</span>    <span class="o">------------------------------------------------------------</span>
<span class="o">&gt;&gt;</span>    <span class="n">Epoch</span> <span class="p">[</span><span class="mi">1</span><span class="o">/</span><span class="mi">8</span><span class="p">],</span> <span class="n">Step</span> <span class="p">[</span><span class="mi">1000</span><span class="o">/</span><span class="mi">12500</span><span class="p">],</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.7001</span><span class="p">,</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">0.368</span>
<span class="o">&gt;&gt;</span>    <span class="o">------------------------------------------------------------</span>
<span class="o">&gt;&gt;</span>    <span class="n">Epoch</span> <span class="p">[</span><span class="mi">1</span><span class="o">/</span><span class="mi">8</span><span class="p">],</span> <span class="n">Step</span> <span class="p">[</span><span class="mi">1250</span><span class="o">/</span><span class="mi">12500</span><span class="p">],</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.4462</span><span class="p">,</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">0.873</span>
<span class="o">&gt;&gt;</span>    <span class="o">------------------------------------------------------------</span>
<span class="o">&gt;&gt;</span>    <span class="n">Epoch</span> <span class="p">[</span><span class="mi">1</span><span class="o">/</span><span class="mi">8</span><span class="p">],</span> <span class="n">Step</span> <span class="p">[</span><span class="mi">1500</span><span class="o">/</span><span class="mi">12500</span><span class="p">],</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0427</span><span class="p">,</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">1.000</span>
<span class="o">&gt;&gt;</span>    <span class="o">------------------------------------------------------------</span>
<span class="o">&gt;&gt;</span>    <span class="n">EARLY</span> <span class="n">STOPPING</span>
</code></pre></div>

<h3>Model Summary</h3>
<p>In viewing neural network architectures as function composition we see
recurrent neural networks can be viewed as a reduce operation on an input
sequence.</p>
<p><img alt="rnn" src="images/RNN-encoding.jpg"></p>
<p>Considering one bit at a time and remembering the previous partial result in
a recurrent or multi-step architecture reduces the problem of learning k-bit
parity to the simple one of learning just 2-bit parity.</p>
<h3>The Architecture</h3>
<p>Below is a diagram showing the architecture of the LSTM.</p>
<p><img alt="xor lstm" src="images/xor_lstm_.jpg"></p>
<div class="highlight"><pre><span></span><code><span class="n">model</span>

<span class="o">&gt;&gt;</span>    <span class="n">XORLSTM</span><span class="p">(</span>
<span class="o">&gt;&gt;</span>      <span class="p">(</span><span class="n">lstm</span><span class="p">):</span> <span class="n">LSTM</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="o">&gt;&gt;</span>      <span class="p">(</span><span class="n">fc</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="o">&gt;&gt;</span>      <span class="p">(</span><span class="n">activation</span><span class="p">):</span> <span class="n">Sigmoid</span><span class="p">()</span>
<span class="o">&gt;&gt;</span>    <span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">model</span><span class="p">(</span><span class="n">XOR</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">generate_data</span><span class="p">(</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>

<span class="o">&gt;&gt;</span>    <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">sampleX</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="o">&gt;&gt;</span>    <span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span>
<span class="o">&gt;&gt;</span>            <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span>
<span class="o">&gt;&gt;</span>            <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">])</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">sampleX</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># cumulative parity of sample bit</span>

<span class="o">&gt;&gt;</span>    <span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span>
<span class="o">&gt;&gt;</span>            <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span>
<span class="o">&gt;&gt;</span>            <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">])</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">sampleY</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="o">&gt;&gt;</span>    <span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span>
<span class="o">&gt;&gt;</span>            <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span>
<span class="o">&gt;&gt;</span>            <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">])</span>
</code></pre></div>

<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script></article>



        </main> 

        <footer>
                <p>&mdash; &centerdot; &centerdot; &centerdot;</p> 
                <!---
                <a href='/about'>about</a> &compfn;
                <a href='#'>book</a> &compfn;
                <a href="mailto:nehemiahcampbell@hotmail.co.uk">contact</a>
                -->
        </footer>

            </div>
    </body>
</html>
